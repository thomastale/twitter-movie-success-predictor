{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Twitter Movie Success: Getting Data (Draft 2)</h2>\n",
        "Thomas Le"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import pandas as pd \n",
        "import csv\n",
        "import GetOldTweets3 as got\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import itertools\n",
        "import collections\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from textblob import TextBlob\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "from datetime import timedelta"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consumer_key = 'm3EuCXkTyC830AHQSCDzAQ6SD' \n",
        "consumer_secret = 'GjagyDgwlk8mjRoVncXaS1bAjkKv92hBuPzpTuReoX2uBHZ2MW'\n",
        "\n",
        "access_token = '1158877831113465856-n2zYtW8kKViUJ3mYA3Vt86VmZcm536'\n",
        "access_token_secret = 'UDbd3Xaqaf6zjtnzvQ5mk2BEuB2PcWsiZRyHNzk707bYQ'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for importing files\n",
        "\n",
        "bo_data = pd.read_csv('box_office_data.csv') \n",
        "display(bo_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Functions</h2>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# this function takes all the words in the tweets given, splits them and removes all stop words, title name, symbols, and popular occuring movie related words. The remaining words, the top 10 are taken and analysed for their sentiment value (-1 to 1). The sentiment value of these top 10 words are taken and averaged to give single aggregate sentiment value for that query.\n",
        "\n",
        "def averageSentiment(movie_title, all_tweets):\n",
        "    \n",
        "    topwords_list = []\n",
        "    \n",
        "    collection_words = movie_title.lower().split()\n",
        "    symbols = ['!','|',',','!','...','-']\n",
        "    random = ['movie','movies','@youtube','trailer','video','official']\n",
        "    stop_words = set(stopwords.words('english') + collection_words + symbols + random)\n",
        "    \n",
        "    words_in_tweets = []\n",
        "    for tweets in all_tweets:\n",
        "        words_in_tweets.append(tweets.lower().split())\n",
        "    \n",
        "    tweets_nsw = []\n",
        "\n",
        "    for tweet_words in words_in_tweets:\n",
        "        for word in tweet_words:\n",
        "            if not word in stop_words:\n",
        "                tweets_nsw.append(word) #nsw: no stop words\n",
        "                \n",
        "    all_words= list(itertools.chain(tweets_nsw))\n",
        "    counts= collections.Counter(all_words)\n",
        "    topwords_list = np.array(counts.most_common(10)) \n",
        "    topwords_list = topwords_list[:,0]\n",
        "    \n",
        "    sentiments = [TextBlob(tweet) for tweet in topwords_list]\n",
        "    polarities = [word.sentiment.polarity for word in sentiments]  \n",
        "\n",
        "    avgsentiment = sum(polarities)/len(polarities)\n",
        "    avgsentiment = round(avgsentiment,4)\n",
        "    \n",
        "    return(avgsentiment)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function scrapes Twitter for tweets for a query between certain dates and returns a list of: the movie title, number of tweets, number of likes for all those tweets, number of retweets for all those tweets, and the average sentiment.\n",
        "\n",
        "#global variables\n",
        "listno = []\n",
        "tweet_data = []\n",
        "list_of_tweets = []\n",
        "retweet_list = []\n",
        "output = []\n",
        "query= 0\n",
        "\n",
        "def scraper(listno, query, since, until, maxtweets, output):\n",
        "    \n",
        "    #put them here again to reset everytime a movie is searched\n",
        "    listno = []\n",
        "    list_of_tweets = []\n",
        "    retweet_list = []\n",
        "    \n",
        "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(query)\\\n",
        "                                           .setSince(since)\\\n",
        "                                           .setUntil(until)\\\n",
        "                                           .setMaxTweets(maxtweets)\n",
        "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "    for tweet in tweets:\n",
        "        listno.append(tweet.favorites)\n",
        "        list_of_tweets.append(tweet.text)\n",
        "        retweet_list.append(tweet.retweets)\n",
        "    \n",
        "    avgsentiment = averageSentiment(query, list_of_tweets)\n",
        "    \n",
        "    listno2 = [query] +[len(listno)]+[sum(listno)]+[sum(retweet_list)]+[avgsentiment]\n",
        "    \n",
        "    output.append(listno2)\n",
        "    \n",
        "    return output"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#second scraper only difference is: adds query to hashtag line\n",
        "\n",
        "#global variables\n",
        "listno = []\n",
        "tweet_data2 = []\n",
        "list_of_tweets = []\n",
        "retweet_list = []\n",
        "output = []\n",
        "\n",
        "def scraper2(listno, query, since, until, maxtweets, output):\n",
        "    \n",
        "    #put them here again to reset everytime a movie is searched\n",
        "    listno = []\n",
        "    list_of_tweets = []\n",
        "    retweet_list = []\n",
        "    \n",
        "    query = str('#') + ''.join(query.lower().split())\n",
        "    \n",
        "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(query)\\\n",
        "                                           .setSince(since)\\\n",
        "                                           .setUntil(until)\\\n",
        "                                           .setMaxTweets(maxtweets)\n",
        "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "    for tweet in tweets:\n",
        "        listno.append(tweet.favorites)\n",
        "        list_of_tweets.append(tweet.text)\n",
        "        retweet_list.append(tweet.retweets)\n",
        "    \n",
        "    avgsentiment = averageSentiment(query, list_of_tweets)\n",
        "    \n",
        "    listno2 = [query] +[len(listno)]+[sum(listno)]+[sum(retweet_list)]+[avgsentiment]\n",
        "    \n",
        "    output.append(listno2)\n",
        "    \n",
        "    return output"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Twitter: Do more people use hashtags or text?</h2>\n",
        "The following two code cell blocks are here to demonstrate some insights into user behaviour on Twitter. Disclaimer: The sample for these was very small (limited processing power to scrape more tweets), so more research and data is warranted before taking any actions.\n",
        "<p></p>\n",
        "Four movies were tested by querying both their title as text in addition to their title as a hashtag. \n",
        "<p></p>\n",
        "The way the GetOldTweets3 library works in this context is that a query of 'Zootopia' will return tweets showing both 'Zootopia' <b>and</b> '#zootopia', so for the number of tweets shown for 'Zootopia' that will include the total count for tweets with and without the hashtag.\n",
        "<p></p>\n",
        "For movie titles with names that are multiple words, the query of 'Finding Dory' for example will only return those with 'Finding Dory' (including the space). For the total counts for these, adding the number of tweets for both 'Finding Dory' and '#findingdory' will be necessary to get the total number of tweets about that movie.\n",
        "<p></p>\n",
        "Though testing this on movies with a single word title may seem redundant, I thought it prudent for the sake of seeing if having a shorter title had any affect on people more easily hashtagging it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# script to test whether hashtags or regular name is a better search query\n",
        "# sqt = search query table\n",
        "\n",
        "#this part to create the table\n",
        "sqt_data = pd.read_csv('box_office_data.csv', index_col = 'Movie Title') \n",
        "sqt = sqt_data.loc[['Finding Dory', 'Suicide Squad', 'Zootopia', 'Deadpool']]\n",
        "sqt = sqt.reset_index()[['Movie Title','Date Released']]\n",
        "#display(sqt)\n",
        "\n",
        "hashtag_list = []\n",
        "\n",
        "for i in sqt['Movie Title']:\n",
        "    tagged = str('#') + ''.join(i.lower().split())\n",
        "    hashtag_list.append(tagged)\n",
        "   \n",
        "sqt2 = pd.DataFrame(hashtag_list, columns = ['Movie Title'])\n",
        "sqt2['Date Released'] = sqt['Date Released']\n",
        "sqt = sqt.append(sqt2, sort = False) #ignore_index = true\n",
        "sqt.sort_values(by=['Date Released'], inplace=True, ascending=True)\n",
        "display(sqt)\n",
        "print('')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('STARTED SCRAPING SQT TABLE AT')\n",
        "print(datetime.datetime.now())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ok now actually seeing which has more tweets\n",
        "\n",
        "list_sqt = []\n",
        "\n",
        "sinceDELTA = timedelta(weeks=5)\n",
        "untilDELTA = timedelta(weeks=4, days=6)\n",
        "sqt_output = []\n",
        "\n",
        "for i in sqt['Movie Title']:\n",
        "   movie_title = i\n",
        "   for j in sqt['Date Released']:\n",
        "        j = datetime.datetime.strptime(j, '%m/%d/%y').date()\n",
        "        since = str(j - sinceDELTA)\n",
        "        until = str(j - untilDELTA)\n",
        "   scraper(list_sqt, movie_title, since, until, 0, sqt_output)\n",
        "\n",
        "sqt_test = pd.DataFrame(sqt_output, columns = ['movie title','total number of tweets','total likes','retweets','average tweet sentiment'])\n",
        "display(sqt_test)\n",
        "sqt_test.to_csv('hashtag_or_regular_text.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it seems that the average user of Twitter does not use hashtags as much as the text equivalent of a movie title. From these samples, we see that about 15% of all tweets (with some form of the movie title) are posted with the hashtag version as opposed to 85% using the movie title as just text.\n",
        "<p></p>\n",
        "Initial hypothesis from this finding was that the average Twitter user uses twitter more to let their friends know what they're up to, whereas users using hashtags are trying to promote a movie.\n",
        "<p></p>\n",
        "This hypothesis is supported by the higher percentage of likes and retweets for the tweets queried with hashtags. Perhaps users with more followers (movie accounts, actors, influencers, etc) are tweeting with hashtags and garnering more likes and retweets, but the total users talking about the movie casually to their twitter social circles use just the text form of the movie title.\n",
        "<p></p>\n",
        "These findings are not suggesting any action, only thought useful to keep in mind during any subsequent data scraping on twitter and for the remainder of this project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Gathering final set of movie data</h2>\n",
        "If the movie has a one word title, then only query by its title and the returned tweets analysis will include tweets for both the text version 'MovieTitle' and the tweets with a hashtag version '#movietitle'.\n",
        "<p></p>\n",
        "If the movie has a multiple word title, then run two queries: one query to return the tweets of the text version 'Multiple Word Movie Title' and one query to return the tweet analysis for the hashtag version '#multiplewordmovietitle'. These analyses will be added together to return one final row of data for the tweet analysis of that movie."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('STARTED SCRAPING TABLE AT')\n",
        "print(datetime.datetime.now())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sinceDELTA = timedelta(weeks=5)\n",
        "untilDELTA = timedelta(weeks=4, days=6)\n",
        "maxtweets = 0\n",
        "tweet_data = []\n",
        "date_counter = 0\n",
        "\n",
        "for i in bo_data['Movie Title']:\n",
        "    titleLength = len(i.split())\n",
        "    \n",
        "    movie_title = i\n",
        "    movie_hashtag = ''.join(movie_title.lower().split()) #weird zootopia glitch happens unless i do this (theres already a hashtag form statement in scraper2\n",
        "    \n",
        "    #increment date so the time period (of which to scrape for tweets) will change for each movie depending on day of release\n",
        "    j = datetime.datetime.strptime(bo_data['Date Released'][date_counter], '%m/%d/%y').date()\n",
        "    since = str(j - sinceDELTA)\n",
        "    until = str(j - untilDELTA) \n",
        "    date_counter += 1\n",
        "    \n",
        "    if titleLength > 1:\n",
        "        \n",
        "        multiple_list = []\n",
        "        multiple_list_h = [] #hashtagged\n",
        "        tweets1 = []\n",
        "        tweets2 = []\n",
        "\n",
        "        #regular text\n",
        "        a = scraper(multiple_list, movie_title, since, until, maxtweets, tweets1)\n",
        "        a = np.array(a[0])\n",
        "\n",
        "        #hashtag text\n",
        "        b = scraper2(multiple_list_h, movie_hashtag, since, until, maxtweets, tweets2)\n",
        "        b = np.array(b[0])\n",
        "        \n",
        "        #empty out previous loop of combined regular text and hashtag text values    \n",
        "        list3 = []\n",
        "        \n",
        "        #combining the tweet values for both regular and hashtag\n",
        "        for k in range (1,5):\n",
        "            c = float(a[k])+ float(b[k]) #loops through each tweet analysis value\n",
        "            list3.append(c)   \n",
        "        list3.insert(0, movie_title) #insert original movie title into row of data\n",
        "        \n",
        "        #append combined data (row of 1 movie data) into list of rows\n",
        "        tweet_data.append(list3)\n",
        "\n",
        "    elif titleLength == 1:\n",
        "        \n",
        "        single_list = [] \n",
        "        tweets3 = []\n",
        "            \n",
        "        #both regular text and hashtag text for single word movie title\n",
        "        d = scraper(single_list, movie_title, since, until, 0, tweets3)\n",
        "        d = np.array(d[0])\n",
        "        \n",
        "        #append row of 1 movie data into list of rows\n",
        "        tweet_data.append(d)\n",
        "  \n",
        "twitter_movie_data = pd.DataFrame(tweet_data, columns = ['movie title','total number of tweets','total likes','retweets','average tweet sentiment'])\n",
        "display(twitter_movie_data)\n",
        "\n",
        "twitter_movie_data.to_csv('twitter_movie_data.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('COMPLETED SCRAPING TABLE AT')\n",
        "print(datetime.datetime.now())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_movie_data = pd.DataFrame(tweet_data, columns = ['movie title','total number of tweets','total likes','retweets','average tweet sentiment'])\n",
        "\n",
        "display(twitter_movie_data)\n",
        "\n",
        "twitter_movie_data.to_csv('twitter_movie_data.csv', index = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}